{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker MultiModel Endpoints\n",
    "\n",
    "With Amazon SageMaker MultiModel Endpoints (internal feature name), customers will be able to create an Endpoint which can host multiple models behind the same Endpoint. These Endpoints are well suited to cases where there are a large number of models that can be served from a shared inference container and when the customer performing an InvokeEndpoint request tolerates occasional cold start related latency penalties for invoking infrequently used models.\n",
    "\n",
    "At a high level, Amazon SageMaker manages the lifetime of the models in-memory for MultiModel Endpoints. When an invocation request is made for a particular model, Amazon SageMaker routes to a particular instance, downloads the model from S3 to that instance, and loads the required model to the memory of the customer container. Then Amazon SageMaker performs an invocation on the model. If the model is already loaded in memory, the invocation will be fast since the downloading and loading steps are skipped. If a model is 'popular' due to frequent invocations of that model, then it is likely to be in memory already and the inference requests should also be served fast.\n",
    "\n",
    "---\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. [Introduction to MXNet Model Server (MMS)](#Introduction-to-MXNet-Model-Server-(MMS))\n",
    "1. [Building and registering a container using MMS](#Building-and-registering-a-container-using-MMS)\n",
    "1. [Set up Boto to use private SageMaker fields](#Set-up-Boto-to-use-private-SageMaker-fields)\n",
    "1. [Upload model artifacts to S3](#Upload-model-artifacts-to-S3)\n",
    "1. [Import models into hosting](#Import-models-into-hosting)\n",
    "1. [Invoke a model](#Invoke-a-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to MXNet Model Server (MMS)\n",
    "\n",
    "[MXNet Model Server](https://github.com/awslabs/mxnet-model-server) is an open source framework for serving machine learning models. It provides the HTTP frontend and model management capabilities required by MultiModel Endpoints to host multiple models within a single container, load models into and unload models out of the container dynamically, and performing inference on a specified loaded model.\n",
    "\n",
    "Though the name implies the models are MXNet models, MMS supports a pluggable backend handler where you can implement your own algorithm.\n",
    "\n",
    "This example uses a handler that supports loading and inference for MXNet models, which we will inspect below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cat container/model_handler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of note are the `handle(data, context)` and `initialize(self, context)` methods.\n",
    "\n",
    "The `initialize` method will be called when a model is loaded into memory. In this example, it loads the model artifacts at `model_dir` into MXNet.\n",
    "\n",
    "The `handle` method will be called when invoking the model. In this example, it validates the input payload and then forwards the input to MXNet, returning the output.\n",
    "\n",
    "This handler class is instantiated for every model loaded into the container, so state in the handler is not shared across models.\n",
    "\n",
    "### Handling Out Of Memory conditions\n",
    "If MXNet fails to load the model due to lack of memory, a `MemoryError` is raised. Any time a model cannot be loaded due to lack of memory or any other resource, a `MemoryError` must be raised. MMS will interpret the `MemoryError`, and return a 507 HTTP status code to SageMaker, where SageMaker will initiate unloading unused models to reclaim resources so the requested model can be loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and registering a container using MMS\n",
    "The shell script below will build a docker image which uses MMS as the front end, and `container/model_handler.py` that we inspected above as the backend handler. It will then upload the image to an ECR repository in your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=demo-sagemaker-multimodel\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the SageMaker SDK version \n",
    "\n",
    "A recent version (1.39.0) of sagemaker python SDK had introduced an [issue](https://github.com/aws/sagemaker-python-sdk/issues/1034) with get_execution_role(). This has been fixed in version 1.39.1\n",
    "\n",
    "If your notebook was created with this version of the SDK, please run the two cells below to upgrade to a new version and reload to get the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SageMaker python SDK version 1.39.1 which fixes a bug in get_execution_role() API\n",
    "!echo 'y' | pip uninstall sagemaker\n",
    "!pip install sagemaker==1.39.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart the Kernel after the SageMaker Python SDK version update\n",
    "\n",
    "Restart the Kernel to ensure the new SageMaker Python SDK version installed above is used for the API calls below:\n",
    "\n",
    "\"Kernel\" -> \"Restart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Boto to use private SageMaker fields\n",
    "The new API fields required to create and invoke MultiModel Endpoints are packaged in this sample notebook. Below we install them into Boto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure add-model --service-model file://sagemaker-2017-07-24.normal.json --service-name sagemaker-multimodel-endpoints\n",
    "!aws configure add-model --service-model file://sagemaker-runtime.normal.json --service-name sagemaker-runtime-multimodel-endpoints\n",
    "\n",
    "import boto3\n",
    "\n",
    "sm_client = boto3.client(service_name='sagemaker-multimodel-endpoints')\n",
    "runtime_sm_client = boto3.client(service_name='sagemaker-runtime-multimodel-endpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment\n",
    "Define the S3 bucket and prefix where the model artifacts that will be invokable by your MultiModel Endpoint will be located.\n",
    "\n",
    "Also define the IAM role that will give SageMaker access to the model artifacts and ECR image that was created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket = 'sagemaker-{}-{}'.format(region, account_id)\n",
    "prefix = 'demo-multimodel-endpoint'\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload model artifacts to S3\n",
    "In this example we will use a ResNet 18 and ResNet 152 model, both trained on the ImageNet datset. First we will download the pre trained models from MXNet's model zoo, then upload them to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir resnet_18\n",
    "cd resnet_18\n",
    "wget -O resnet-18-0000.params http://data.mxnet.io/models/imagenet/resnet/18-layers/resnet-18-0000.params \n",
    "wget -O resnet-18-symbol.json http://data.mxnet.io/models/imagenet/resnet/18-layers/resnet-18-symbol.json \n",
    "wget -O synset.txt http://data.mxnet.io/models/imagenet/synset.txt \n",
    "echo '[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]' > resnet-18-shapes.json\n",
    "cd ..\n",
    "tar -zcvf resnet_18.tar.gz -C resnet_18 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir resnet_152\n",
    "cd resnet_152\n",
    "wget -O resnet-152-0000.params http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-0000.params \n",
    "wget -O resnet-152-symbol.json http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-symbol.json \n",
    "wget -O synset.txt http://data.mxnet.io/models/imagenet/synset.txt \n",
    "echo '[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]' > resnet-152-shapes.json\n",
    "cd ..\n",
    "tar -zcvf resnet_152.tar.gz -C resnet_152 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import ClientError\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    s3.meta.client.head_bucket(Bucket=bucket)\n",
    "except ClientError:\n",
    "    s3.create_bucket(Bucket=bucket)\n",
    "\n",
    "models = {'resnet_18.tar.gz', 'resnet_152.tar.gz'}\n",
    "\n",
    "for model in models:\n",
    "    key = os.path.join(prefix, model)\n",
    "    with open(model, 'rb') as file_obj:\n",
    "        s3.Bucket(bucket).Object(key).upload_fileobj(file_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models into hosting\n",
    "A big difference for MultiModel endpoints is that when creating the Model entity, the container's `ModelDataUrl` is the S3 prefix where the model artifacts that are invokable by the endpoint are located. The rest of the S3 path will be specified when actually invoking the model.\n",
    "\n",
    "The `Mode` of container is specified as `MultiModel` to signify that the container will host multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = 'DEMO-MultiModelModel' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_url = 'https://s3-{}.amazonaws.com/{}/{}/'.format(region, bucket, prefix)\n",
    "container = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account_id, region, 'demo-sagemaker-multimodel')\n",
    "\n",
    "print('Model name: ' + model_name)\n",
    "print('Model data Url: ' + model_url)\n",
    "print('Container image: ' + container)\n",
    "\n",
    "container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_url,\n",
    "    'Mode': 'MultiModel'\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "Endpoint config creation works the same way it does as single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = 'DEMO-MultiModelEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint config name: ' + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.m5.4xlarge',\n",
    "        'InitialInstanceCount': 2,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': model_name,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Similarly, endpoint creation works the same way as for single model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = 'DEMO-MultiModelEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Endpoint name: ' + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print('Endpoint Arn: ' + create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print(\"Endpoint Arn: \" + resp['EndpointArn'])\n",
    "print(\"Endpoint Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke a model\n",
    "Now we invoke the models that we uploaded to S3 previously. The first invocation of a model may be slow, since behind the scenes, SageMaker is downloading the model artifacts from S3 to the instance and loading it into the container.\n",
    "\n",
    "First we will download an image of a cat as the payload to invoke the model, then call InvokeEndpoint to invoke the ResNet 18 model. The `TargetModel` field is concatenated with the S3 prefix specified in `ModelDataUrl` when creating the model, to generate the location of the model in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O cat.jpg https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/python/predict_image/cat.jpg\n",
    "\n",
    "with open('cat.jpg', 'rb') as f:\n",
    "    payload = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    TargetModel='resnet_18.tar.gz', # this represents the rest of the S3 path where the model artifacts are located\n",
    "    Body=payload)\n",
    "\n",
    "print(*json.loads(response['Body'].read()), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we invoke the same ResNet 18 model a 2nd time, it is already downloaded to the instance and loaded in the container, so inference is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    TargetModel='resnet_18.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(*json.loads(response['Body'].read()), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke another model\n",
    "Exercising the power of a MultiModel Endpoint, we can specify a different model (resnet_152.tar.gz) as `TargetModel` and perform inference on it using the same Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    TargetModel='resnet_152.tar.gz',\n",
    "    Body=payload)\n",
    "\n",
    "print(*json.loads(response['Body'].read()), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke many models\n",
    "We can add more models to the endpoint without having to update the endpoint. Below we are adding a 3rd model, `squeezenet_v1.0`. To demonstrate hosting multiple models behind the endpoint, this model is duplicated 10 times with a slightly different name in S3. In a more realistic scenario, these could be 10 new different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "mkdir squeezenet_v1.0\n",
    "cd squeezenet_v1.0\n",
    "wget -O squeezenet_v1.0-0000.params http://data.mxnet.io/models/imagenet/squeezenet/squeezenet_v1.0-0000.params\n",
    "wget -O squeezenet_v1.0-symbol.json http://data.mxnet.io/models/imagenet/squeezenet/squeezenet_v1.0-symbol.json\n",
    "wget -O synset.txt http://data.mxnet.io/models/imagenet/synset.txt\n",
    "echo '[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]' > squeezenet_v1.0-shapes.json \n",
    "cd ..\n",
    "tar -zcvf squeezenet_v1.0.tar.gz -C squeezenet_v1.0 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'squeezenet_v1.0.tar.gz'\n",
    "\n",
    "for x in range(0, 10):\n",
    "    s3_file_name = 'demo-subfolder/squeezenet_v1.0_{}.tar.gz'.format(x)\n",
    "    key = os.path.join(prefix, s3_file_name)\n",
    "    with open(file, 'rb') as file_obj:\n",
    "        s3.Bucket(bucket).Object(key).upload_fileobj(file_obj)\n",
    "    models.add(s3_file_name)\n",
    "    \n",
    "print('Number of models: {}'.format(len(models)))\n",
    "print('Models: {}'.format(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading the SqueezeNet models to S3, we will invoke the endpoint 100 times, randomly choosing from one of the 12 models behind the S3 prefix for each invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "results = defaultdict(int)\n",
    "\n",
    "for x in range(0, 100):\n",
    "    target_model = random.choice(tuple(models))\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/x-image',\n",
    "        TargetModel=target_model,\n",
    "        Body=payload)\n",
    "\n",
    "    results[json.loads(response['Body'].read())[0]] += 1\n",
    "    \n",
    "print(*results.items(), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating a model\n",
    "To update a model, you would follow the same approach as above and add it as a new model. For example, if you have retrained the `resnet_18.tar.gz` model and wanted to start invoking it, you would upload the updated model artifacts behind the S3 prefix with a new name such as `resnet_18_v2.tar.gz`, and then change the `TargetModel` field to invoke `resnet_18_v2.tar.gz` instead of `resnet_18.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Delete the hosting resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
